# B2B Diagnostic Research Framework (Enhanced with Maya)
## The 11-Section Intelligence Report

---

## Header Note

**This is the enhanced version of the B2B Diagnostic Framework, expanded to include Maya - our Technical Content Intelligence Specialist.**

The original 9-section framework has been augmented with two new sections focused on content funnel performance and technical content health. This enhancement enables deeper analysis of how content drives business outcomes and identifies structural optimization opportunities that impact discoverability and conversion.

**Key Enhancements:**
- **Section 10**: Content Funnel Performance & Financial Impact (Maya)
- **Section 11**: Technical Content Health & Structural Optimization (Maya)
- **Updated Diagnostic Tiers**: Adjusted time allocations and section coverage to accommodate Maya's analysis
- **Maintained Compatibility**: Original 9-section diagnostics remain available for faster assessments

---

## Overview

This framework enables rapid, ethical assessment of any B2B company using only publicly available information. The output is a comprehensive diagnostic report that demonstrates deep understanding and identifies specific growth opportunities.

**Core Principles:**
- Ethical research (public sources only)
- Fast execution (15-120 minutes depending on tier)
- Credible insights (evidence-based assessments)
- Actionable opportunities (specific recommendations)

---

## Section 1: Business Model, ICP & GTM Motion

### Purpose
Understand what they sell, who they sell to, and how they go to market.

### Key Questions
- What problem do they solve and for whom?
- Who is their ideal customer profile (role, company size, industry)?
- What's their pricing model and deal complexity?
- Are they product-led, sales-led, or hybrid?
- What's their growth stage and funding status?

### Public Data Sources
- Company website (product pages, pricing, case studies)
- LinkedIn company page (employee count, roles, growth)
- Crunchbase / PitchBook (funding, investors, valuation)
- Job postings (AE vs SDR ratio, product marketing roles)
- Product Hunt / G2 / Capterra (product positioning, reviews)

### Assessment Criteria
- **ICP Clarity** (1-5): How clearly defined is their target customer?
- **GTM Maturity** (1-5): Sophistication of their go-to-market motion
- **Model Viability** (1-5): Does the business model align with market expectations?

### Output Format
```
Business Model: [SaaS / Platform / Marketplace / etc.]
Primary ICP: [Role + Company Size + Industry]
GTM Motion: [PLG / Sales-Led / Hybrid] with [Maturity Assessment]
Funding Stage: [Pre-seed / Seed / Series A / etc.] - $[Amount]
Key Insight: [One-line strategic observation]
```

---

## Section 2: Market Context & Competitive Positioning

### Purpose
Map where they sit in the market landscape and vs. competitors.

### Key Questions
- What market category do they play in?
- Who are their direct and indirect competitors?
- What's their unique differentiation claim?
- Are they positioned as premium, mid-market, or budget?
- What's the market maturity and growth trajectory?

### Public Data Sources
- Competitor websites and messaging
- Industry analyst reports (Gartner, Forrester quadrants)
- LinkedIn "People Also Viewed" for competitive set
- Comparison pages on G2, Capterra, TrustRadius
- Industry news and funding announcements

### Assessment Criteria
- **Differentiation Clarity** (1-5): How distinct is their positioning?
- **Competitive Strength** (1-5): How defensible is their market position?
- **Category Authority** (1-5): Are they seen as category leaders?

### Output Format
```
Market Category: [Category name + maturity stage]
Direct Competitors: [Top 3-5 competitors]
Positioning: [How they differentiate in one sentence]
Competitive Gap: [Opportunity they could own but don't]
Strategic Risk: [Biggest competitive threat]
```

---

## Section 3: Narrative Strength & Category POV

### Purpose
Evaluate how compelling their story is and whether they own a perspective.

### Key Questions
- Do they have a clear, memorable narrative?
- Do they articulate a "category POV" or just describe features?
- Is their messaging founder-led or generic?
- Do they have contrarian/bold takes or play it safe?
- What's their "why now?" story?

### Public Data Sources
- Homepage messaging and About page
- Founder blog posts and LinkedIn content
- Company blog and thought leadership
- Pitch deck (if publicly available)
- Podcast appearances and interviews

### Assessment Criteria
- **Narrative Clarity** (1-5): Is their story easy to understand and repeat?
- **Category POV** (1-5): Do they define the category or just play in it?
- **Founder Voice** (1-5): Is there authentic founder perspective or corporate speak?

### Output Format
```
Core Narrative: [Their story in 1-2 sentences]
Category POV: [Do they have one? What is it?]
Messaging Strength: [Strong / Average / Weak] with rationale
Voice Authenticity: [Founder-driven / Corporate / Missing]
Opportunity: [What POV could they own that they're missing?]
```

---

## Section 4: Content Footprint: Authority, Consistency, Quality, SEO/AEO

### Purpose
Audit their content presence, authority, and discoverability.

### Key Questions
- How often do they publish valuable content?
- What's the quality and depth of their content?
- Do they rank for relevant search terms?
- Are they cited in AI responses (AEO visibility)?
- Do they have content gaps competitors are filling?

### Public Data Sources
- Company blog (publication frequency, topics, depth)
- Google search for key terms (ranking position)
- ChatGPT / Perplexity / Gemini (AI visibility check)
- Ahrefs / SEMrush (if available via free tier)
- Backlink analysis (who links to them?)

### Assessment Criteria
- **Content Volume** (1-5): Publishing frequency and consistency
- **Content Depth** (1-5): Substance vs. surface-level
- **SEO Performance** (1-5): Organic search visibility
- **AEO Visibility** (1-5): Cited in AI responses
- **Authority Signals** (1-5): Backlinks, media citations, thought leadership

### Output Format
```
Publishing Frequency: [X posts/month on blog, Y on LinkedIn]
Content Quality Score: [1-5] with examples
SEO Performance: [Strong / Moderate / Weak] - Key terms ranking
AEO Visibility: [High / Medium / Low] - AI citation rate
Content Gaps: [Top 3 topics competitors own that they don't]
Authority Score: [1-5] based on backlinks, citations, media
```

---

## Section 5: Public Founder Presence & Credibility Signals

### Purpose
Assess founder/leadership visibility and thought leadership.

### Key Questions
- Are founders active and visible publicly?
- Do they have personal brands or corporate anonymity?
- What's their LinkedIn following and engagement?
- Do they speak at events, appear on podcasts, write articles?
- What's their professional pedigree (ex-Google, ex-McKinsey, etc.)?

### Public Data Sources
- Founder LinkedIn profiles (activity, followers, engagement)
- Twitter/X presence and engagement
- Podcast guest appearances (search Podcast Notes, Listen Notes)
- Speaking engagements (event websites, YouTube)
- Personal blogs or newsletters
- Crunchbase bios and previous ventures

### Assessment Criteria
- **Founder Visibility** (1-5): How active and present are they?
- **Credibility Signals** (1-5): Pedigree, track record, expertise
- **Engagement** (1-5): Do they build community or broadcast?

### Output Format
```
Founder Profile: [Name + Background in one line]
LinkedIn Presence: [Follower count + Engagement level]
Thought Leadership: [Active / Moderate / Minimal] with examples
Credibility Signals: [Previous companies, achievements, pedigree]
Personal Brand Strength: [Strong / Developing / Absent]
Opportunity: [How they could amplify founder visibility]
```

---

## Section 6: Customer Sentiment (Public Sources Only)

### Purpose
Gauge customer satisfaction and sentiment without invasive tactics.

### Key Questions
- What are customers saying in public reviews?
- What's the sentiment trend (improving vs. declining)?
- What do they love? What frustrates them?
- Are there vocal advocates or public detractors?
- How responsive is the company to feedback?

### Public Data Sources
- G2 / Capterra / TrustRadius reviews
- Product Hunt comments and upvotes
- Reddit mentions (search r/SaaS, relevant subreddits)
- Twitter/X mentions and sentiment
- LinkedIn recommendations and testimonials
- Case studies and customer quotes on website

### Assessment Criteria
- **Overall Sentiment** (1-5): Positive, neutral, or negative?
- **Review Volume** (1-5): Are customers vocal about them?
- **Response Quality** (1-5): Do they engage with feedback well?

### Output Format
```
Review Score: [Avg rating across G2, Capterra, etc.]
Customer Sentiment: [Positive / Mixed / Negative] with examples
Common Praise: [Top 2-3 things customers love]
Common Complaints: [Top 2-3 pain points]
Vocal Advocates: [Do they have visible champions?]
Responsiveness: [How well do they handle public feedback?]
```

---

## Section 7: Distribution Maturity Across Owned/Earned Channels

### Purpose
Evaluate their content distribution strategy and channel effectiveness.

### Key Questions
- What channels are they active on?
- Which channels are working vs. dormant?
- Do they have owned audiences (email list, community)?
- Are they earning distribution (media, partnerships, guest content)?
- What's their paid strategy visibility?

### Public Data Sources
- LinkedIn company page activity and engagement
- Twitter/X activity and followers
- YouTube channel (if exists) - subscriber count, views
- Newsletter (if public) - content quality, frequency
- Podcast (if exists) - episode cadence, guests
- Media mentions (Google News search)
- Guest articles and contributed content

### Assessment Criteria
- **Channel Breadth** (1-5): How many channels are they leveraging?
- **Channel Depth** (1-5): Are channels mature or experimental?
- **Earned Distribution** (1-5): Are others amplifying their content?

### Output Format
```
Active Channels: [List with maturity level]
Strongest Channel: [Which one drives most engagement]
Owned Audience: [Email subscribers, community size if public]
Earned Media: [Media mentions, guest appearances, partnerships]
Distribution Gaps: [Underutilized channels with opportunity]
Maturity Assessment: [Experimental / Growing / Mature]
```

---

## Section 8: Trust Signals (Case Studies, Media Mentions, Proof Assets)

### Purpose
Inventory credibility markers that build market trust.

### Key Questions
- Do they have published case studies with metrics?
- Have they been featured in reputable media?
- Do they showcase logos of impressive customers?
- Are there third-party validations (awards, certifications)?
- Do they have a robust proof library or rely on generic claims?

### Public Data Sources
- Case studies page on website
- Customer logo wall
- Press / Media page
- Google News search for company mentions
- Awards and recognition pages
- Analyst reports mentioning them
- Customer testimonials with attribution

### Assessment Criteria
- **Proof Asset Volume** (1-5): How much credible proof exists?
- **Proof Asset Quality** (1-5): Are they specific or generic?
- **Media Credibility** (1-5): Tier 1 vs. Tier 3 publications?

### Output Format
```
Case Studies: [Count + Quality assessment]
Customer Logos: [Notable brands if public]
Media Mentions: [Count + Notable publications]
Awards/Recognition: [Any third-party validation]
Trust Signal Strength: [Strong / Moderate / Weak]
Proof Gap: [What credibility signals are missing]
```

---

## Section 9: Opportunities & Gaps We Can Solve

### Purpose
Synthesize findings into actionable agency opportunities.

### Key Questions
- Where are the biggest visibility gaps?
- What authority could they build but aren't?
- What content/positioning opportunities are competitors owning?
- What quick wins could build credibility fast?
- What strategic initiatives would 10x their position?

### Public Data Sources
- All findings from sections 1-8 synthesized

### Assessment Criteria
- **Opportunity Size** (1-5): How impactful is the intervention?
- **Execution Ease** (1-5): How quickly can we deliver value?
- **Strategic Fit** (1-5): How aligned with their business goals?

### Output Format
```
Top 3 Opportunities:
1. [Opportunity Name]: [Description + Potential Impact]
2. [Opportunity Name]: [Description + Potential Impact]
3. [Opportunity Name]: [Description + Potential Impact]

Quick Wins (0-30 days):
- [Action 1]
- [Action 2]

Strategic Plays (30-90 days):
- [Initiative 1]
- [Initiative 2]

KiwiQ Fit: [Why we're uniquely positioned to help them]
Pitch Angle: [One-sentence hook for outreach]
```

---

## Section 10: Content Funnel Performance & Financial Impact

### Purpose
Analyze how content drives business outcomes through the funnel and quantify its financial impact.

### Key Questions
- Which content pieces drive the most engagement and conversions?
- How does content map to different funnel stages (awareness, consideration, decision)?
- What's the relationship between content performance and business metrics?
- Are high-performing content types being replicated strategically?
- What content investments yield the highest ROI indicators?

### Public Data Sources
- Blog post engagement signals (comments, shares, time on page if visible)
- LinkedIn post performance (likes, comments, shares, impressions if public)
- G2/Capterra review mentions of content that influenced decisions
- Case study prominence and placement on website
- Gated content offers and their positioning
- Product page traffic patterns (via SimilarWeb, if available)
- Competitor content benchmarking for engagement patterns

### Assessment Criteria
- **Funnel Coverage** (1-5): Do they have content for all buyer stages?
- **Performance Visibility** (1-5): Can we identify top-performing assets?
- **Strategic Replication** (1-5): Are they scaling what works?
- **Conversion Alignment** (1-5): Is high-traffic content mapped to conversion paths?
- **ROI Indicators** (1-5): Evidence that content drives business outcomes?

### Output Format
```
Funnel Stage Coverage:
- Awareness Content: [Quality/Quantity assessment]
- Consideration Content: [Quality/Quantity assessment]
- Decision Content: [Quality/Quantity assessment]

Top-Performing Content:
- [Content piece 1]: [Why it performs + metrics if available]
- [Content piece 2]: [Why it performs + metrics if available]
- [Content piece 3]: [Why it performs + metrics if available]

Content-to-Revenue Indicators:
- [Evidence of content driving demos, signups, or conversions]
- [Customer testimonials mentioning content that influenced decision]
- [High-engagement content with clear CTA paths]

Replication Gaps:
- [Successful content types not being scaled]
- [Missing funnel stages with no content investment]

Financial Impact Hypothesis:
[Estimated impact of content optimization on pipeline/revenue based on visible signals]

Opportunity:
[How content funnel optimization could accelerate growth]
```

---

## Section 11: Technical Content Health & Structural Optimization

### Purpose
Evaluate the technical infrastructure of content for discoverability, user experience, and conversion optimization.

### Key Questions
- Is content structured for both human readers and search engines?
- Are technical SEO fundamentals in place (schema, meta tags, heading hierarchy)?
- Does content architecture support internal linking and topic clustering?
- Are pages optimized for Core Web Vitals and mobile experience?
- Is there a clear content taxonomy and navigation structure?

### Public Data Sources
- Page source code inspection (meta tags, schema markup, heading structure)
- Google Search Console insights (if public presentations or case studies available)
- PageSpeed Insights (Core Web Vitals scores)
- Mobile-friendliness testing (Google Mobile-Friendly Test)
- Site architecture analysis (navigation structure, URL patterns)
- Internal linking patterns (topic clusters, pillar pages)
- Content categorization and taxonomy (blog categories, tags)
- Competitor technical content benchmarking

### Assessment Criteria
- **Technical SEO Health** (1-5): Meta tags, schema, heading structure, alt text
- **Content Architecture** (1-5): Logical structure, internal linking, topic clustering
- **User Experience** (1-5): Page speed, mobile optimization, readability
- **Conversion Infrastructure** (1-5): CTA placement, form optimization, content-to-conversion paths
- **Structural Scalability** (1-5): Can content system support growth?

### Output Format
```
Technical SEO Assessment:
- Meta Tags: [Present/Missing + Quality]
- Schema Markup: [Implemented/Absent + Types used]
- Heading Hierarchy: [Proper/Inconsistent]
- Image Optimization: [Alt text, compression, lazy loading]
- Technical Score: [1-5] with rationale

Content Architecture:
- Navigation Structure: [Clear/Confusing]
- Internal Linking: [Strategic/Minimal/Absent]
- Topic Clustering: [Implemented/Opportunity]
- Pillar Pages: [Present/Missing]
- URL Structure: [SEO-friendly/Generic]
- Architecture Score: [1-5] with rationale

User Experience:
- Core Web Vitals: [Pass/Fail with metrics]
- Mobile Optimization: [Excellent/Good/Poor]
- Page Speed: [Fast/Average/Slow - load time]
- Readability: [Formatting, white space, typography]
- UX Score: [1-5] with rationale

Conversion Infrastructure:
- CTA Placement: [Strategic/Generic/Missing]
- Form Optimization: [Friction level assessment]
- Content-to-Conversion Paths: [Clear/Unclear]
- Gated Content Strategy: [Effective/Needs work]
- Conversion Score: [1-5] with rationale

Technical Content Gaps:
1. [Critical technical issue impacting performance]
2. [Structural weakness limiting scalability]
3. [Optimization opportunity for quick wins]

Competitive Technical Benchmark:
[How their technical content health compares to top 2-3 competitors]

Structural Optimization Priority:
[Top recommendation for technical content improvement with expected impact]
```

---

## Diagnostic Tiers

### Lightning Diagnostic (15 minutes)
**Sections**: 1, 2, 3, 4, 9 (Business, Market, Narrative, Content, Opportunities)
**Coverage**: Fast company assessment for cold outreach qualification
**Maya Involvement**: None (traditional 9-section framework subset)
**Output**: 1-2 pages

### Standard Diagnostic (45 minutes)
**Sections**: All 11 sections with abbreviated Maya analysis
**Coverage**: Comprehensive assessment with moderate depth
**Maya Involvement**: Abbreviated analysis of Sections 10 & 11
- Section 10: High-level funnel coverage and top 3 performing content pieces identified
- Section 11: Basic technical SEO audit (meta tags, schema, page speed) without deep structural analysis
**Output**: 5-8 pages

### Deep Diagnostic (90-120 minutes)
**Sections**: All 11 sections with full Maya depth
**Coverage**: Exhaustive research with competitive benchmarking
**Maya Involvement**: Full depth analysis of Sections 10 & 11
- Section 10: Complete funnel mapping, performance analysis across 8-10 content pieces, ROI indicator research, competitive content benchmarking
- Section 11: Comprehensive technical audit (full SEO health, content architecture deep-dive, UX optimization assessment, conversion infrastructure analysis) with competitive technical benchmarking
**Output**: 12-18 pages + appendices

---

## Ethical Research Guidelines

**Always:**
- Use only publicly available information
- Cite sources for claims and data
- Respect privacy and boundaries
- Document data limitations transparently

**Never:**
- Scrape private or gated data
- Use deceptive tactics to access information
- Make claims without public evidence
- Violate terms of service of platforms

---

**This enhanced framework with Maya transforms public intelligence into strategic advantage while maintaining the highest ethical standards. The addition of content funnel performance analysis and technical content health assessment provides a complete picture of both content effectiveness and optimization opportunities.**
